{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISO 3166-3 Newsletter Parser - Google Colab Edition\n",
    "\n",
    "Parse ISO 3166-3 newsletter PDFs using Google Colab's free GPU!\n",
    "\n",
    "**Setup Steps:**\n",
    "1. Upload your 6 PDF files to this Colab\n",
    "2. Enable GPU: Runtime → Change runtime type → GPU\n",
    "3. Run all cells\n",
    "4. Download the output JSON\n",
    "\n",
    "**Methods Available:**\n",
    "- Method 1: OpenAI GPT-4 Vision (Recommended - Fast & Accurate)\n",
    "- Method 2: DeepSeek-OCR with GPU (Free but slower)\n",
    "- Method 3: Tesseract OCR (Lightweight backup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required packages\n",
    "!pip install -q transformers torch pillow pdf2image PyPDF2 pytesseract openai accelerate\n",
    "!apt-get install -y poppler-utils tesseract-ocr\n",
    "\n",
    "print(\"✓ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Your PDF Files\n",
    "\n",
    "Click the folder icon on the left sidebar, then upload your 6 PDF files:\n",
    "- ISO-TC_46_iso_3166-3_nl_i-1en.pdf\n",
    "- ISO-TC_46_iso_3166-3_nl_i-2en.pdf\n",
    "- ... (through i-6en.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uploaded files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pdf_files = list(Path('.').glob('*.pdf'))\n",
    "print(f\"Found {len(pdf_files)} PDF files:\")\n",
    "for f in sorted(pdf_files):\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "if len(pdf_files) == 0:\n",
    "    print(\"\\n⚠️ No PDFs found! Please upload your files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✓ GPU is available!\")\n",
    "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ GPU not available. Go to Runtime → Change runtime type → GPU\")\n",
    "    print(\"   (You can still run with CPU but it will be slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method: OpenAI GPT-4 Vision (Recommended)\n",
    "\n",
    "**Pros:** Fast, accurate, no GPU needed\n",
    "\n",
    "**Cost:** ~$0.20-$0.50 for all 6 PDFs\n",
    "\n",
    "**Setup:** Enter your OpenAI API key below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "print(\"✓ API key set!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Parser Code\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "from datetime import datetime\n",
    "from io import BytesIO\n",
    "from openai import OpenAI\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "class OpenAIParser:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    def image_to_base64(self, image):\n",
    "        buffered = BytesIO()\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        image.save(buffered, format=\"JPEG\", quality=95)\n",
    "        return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "    \n",
    "    def parse_pdf(self, pdf_path):\n",
    "        print(f\"\\nProcessing: {os.path.basename(pdf_path)}\")\n",
    "        \n",
    "        # Convert to images\n",
    "        print(\"  Converting to images...\")\n",
    "        images = convert_from_path(pdf_path, dpi=200)\n",
    "        print(f\"  ✓ {len(images)} pages\")\n",
    "        \n",
    "        # Prepare images for API\n",
    "        print(\"  Preparing for GPT-4...\")\n",
    "        image_urls = []\n",
    "        for img in images:\n",
    "            b64 = self.image_to_base64(img)\n",
    "            image_urls.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{b64}\", \"detail\": \"high\"}\n",
    "            })\n",
    "        \n",
    "        # Call API\n",
    "        print(\"  Calling OpenAI API...\")\n",
    "        prompt = '''Extract data from this ISO 3166-3 newsletter and return JSON:\n",
    "{\n",
    "  \"newsletter\": {\"id\": \"I-X\", \"date_issued\": \"YYYY-MM-DD\", \"description\": \"...\"},\n",
    "  \"entries\": [{\n",
    "    \"former_country\": {\n",
    "      \"name\": \"...\", \"alpha2\": \"XX\", \"alpha3\": \"XXX\", \"numeric\": \"NNN\",\n",
    "      \"iso_3166_3_alpha4\": \"XXXX\", \"alternative_names\": [\"...\"]\n",
    "    },\n",
    "    \"validity_period\": {\"start\": 1974, \"end\": 2002},\n",
    "    \"transition\": {\n",
    "      \"type\": \"name_changed|merged|divided\",\n",
    "      \"successors\": [{\"name\": \"...\", \"alpha2\": \"XX\", \"alpha3\": \"XXX\", \"numeric\": \"NNN\"}]\n",
    "    },\n",
    "    \"additional_notes\": {\n",
    "      \"historical_context\": \"...\",\n",
    "      \"implementation_notes\": \"...\",\n",
    "      \"reason_for_change\": \"...\"\n",
    "    }\n",
    "  }]\n",
    "}\n",
    "Extract alternative names from notes. Return ONLY valid JSON.'''\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt}, *image_urls]}],\n",
    "            max_tokens=4096,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        response_text = response.choices[0].message.content\n",
    "        json_match = re.search(r'```json\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            response_text = json_match.group(1)\n",
    "        \n",
    "        data = json.loads(response_text)\n",
    "        data['source_file'] = os.path.basename(pdf_path)\n",
    "        data['parsed_at'] = datetime.now().isoformat()\n",
    "        data['tokens_used'] = response.usage.total_tokens\n",
    "        \n",
    "        print(f\"  ✓ Done! ({response.usage.total_tokens} tokens)\")\n",
    "        return data\n",
    "\n",
    "print(\"✓ OpenAI parser ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run OpenAI parsing\n",
    "parser = OpenAIParser(OPENAI_API_KEY)\n",
    "\n",
    "all_results = []\n",
    "total_tokens = 0\n",
    "\n",
    "for pdf_file in sorted(pdf_files):\n",
    "    try:\n",
    "        result = parser.parse_pdf(str(pdf_file))\n",
    "        all_results.append(result)\n",
    "        total_tokens += result['tokens_used']\n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Error: {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Completed! Processed {len(all_results)}/{len(pdf_files)} files\")\n",
    "print(f\"Total tokens: {total_tokens:,}\")\n",
    "print(f\"Estimated cost: ${total_tokens * 0.00001:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save results\n",
    "output = {\n",
    "    \"metadata\": {\n",
    "        \"title\": \"ISO 3166-3 Newsletter Data\",\n",
    "        \"total_newsletters\": len(all_results),\n",
    "        \"parsed_at\": datetime.now().isoformat(),\n",
    "        \"parsing_method\": \"openai-gpt4-vision\"\n",
    "    },\n",
    "    \"newsletters\": all_results\n",
    "}\n",
    "\n",
    "# Add flattened countries list\n",
    "all_countries = []\n",
    "for newsletter in all_results:\n",
    "    for entry in newsletter.get('entries', []):\n",
    "        entry_copy = entry.copy()\n",
    "        entry_copy['source_newsletter'] = {\n",
    "            'id': newsletter['newsletter']['id'],\n",
    "            'date': newsletter['newsletter']['date_issued']\n",
    "        }\n",
    "        all_countries.append(entry_copy)\n",
    "\n",
    "output['all_countries'] = all_countries\n",
    "output['metadata']['total_countries'] = len(all_countries)\n",
    "\n",
    "# Save to file\n",
    "with open('iso_3166_3_parsed.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n✓ Saved to: iso_3166_3_parsed.json\")\n",
    "print(f\"  Newsletters: {len(all_results)}\")\n",
    "print(f\"  Countries: {len(all_countries)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download Results\n",
    "\n",
    "Your parsed JSON file is ready! Click the file to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display download link\n",
    "from google.colab import files\n",
    "\n",
    "if os.path.exists('iso_3166_3_parsed.json'):\n",
    "    print(\"✓ Your file is ready!\")\n",
    "    print(\"\\nClick below to download:\")\n",
    "    files.download('iso_3166_3_parsed.json')\n",
    "else:\n",
    "    print(\"No output file found. Make sure you ran one of the parsing methods above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary\n",
    "if os.path.exists('iso_3166_3_parsed.json'):\n",
    "    with open('iso_3166_3_parsed.json', 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PARSED RESULTS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Newsletters: {data['metadata']['total_newsletters']}\")\n",
    "    print(f\"Total Countries: {data['metadata']['total_countries']}\")\n",
    "    print(f\"\\nExtracted Countries:\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for country in data['all_countries']:\n",
    "        name = country['former_country']['name']\n",
    "        alpha4 = country['former_country'].get('iso_3166_3_alpha4', 'N/A')\n",
    "        newsletter = country['source_newsletter']['id']\n",
    "        print(f\"[{newsletter}] {name} ({alpha4})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ All data successfully extracted!\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
